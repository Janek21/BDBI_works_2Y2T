{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085d4b81-1fd4-4630-a79b-10f3c4f49829",
   "metadata": {},
   "source": [
    "##  Computing Nseries Exercise: \n",
    "\n",
    "Let's use all the scaffolds contained in plant_contaminants.fa to compute the Nseries and other interesting sequence statistics for genome assemblies. \n",
    "\n",
    "  A - let's use all the scaffolds contained in plant_contaminants.fa to compute the Nseries and other interesting sequence statistics for genome assemblies:\n",
    "\n",
    "    1. Write python functions to retrieve this information: N50, L50, N90,L90.\n",
    "    2. Print also the maximum and minimum scaffold length.\n",
    "    3. Use same functions to retrieve the whole Nseries and Lseries. Starting from â‰¥0% and incrementing it 5 by 5, i.e. N0,N5...until N100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a522eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N50 596352\n",
      "L50 13\n",
      "N90 328634\n",
      "L90 26\n",
      "Max scaffold: 745751\n",
      "Min scaffold: 2595\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "file=\"plant_contaminants.fa\"\n",
    "\n",
    "def length(file):\n",
    "    file=\"/home/jj/Desktop/Bioinformatics/2nd_year/2term/ASAB/Seminars/S6_Short_reads_genome/data/\"+file\n",
    "    mx=0\n",
    "    mi=float(\"+inf\")\n",
    "    lenlist=[]\n",
    "    for read in SeqIO.parse(file, \"fasta\"):\n",
    "        l=len(read.seq)\n",
    "        lenlist.append(l)\n",
    "        if l>mx:\n",
    "            mx=l\n",
    "        if l<mi:\n",
    "            mi=l\n",
    "    return sorted(lenlist, reverse=True), mx, mi\n",
    "\n",
    "def N_percentage(lenlist, point):\n",
    "    lssum=sum(lenlist)\n",
    "    #perc=100/point\n",
    "    #tg=lssum/perc\n",
    "    perc=point/100\n",
    "    tg=lssum*perc\n",
    "    c=0\n",
    "\n",
    "    for l in lenlist:\n",
    "        c+=l\n",
    "        if c>=tg:\n",
    "            return l\n",
    "\n",
    "def L_percentage(lenlist, point):\n",
    "    lssum=sum(lenlist)\n",
    "    #perc=100/point\n",
    "    #tg=lssum/perc\n",
    "    perc=point/100\n",
    "    tg=lssum*perc\n",
    "    c_length=0\n",
    "    c=0\n",
    "\n",
    "    for l in lenlist:\n",
    "        c_length+=l\n",
    "        c+=1\n",
    "\n",
    "        if c_length>=tg:\n",
    "            return c\n",
    "\n",
    "\n",
    "def main():\n",
    "    ls, mx, mi=length(file)\n",
    "    print(\"N50\", N_percentage(ls, 50))\n",
    "    print(\"L50\", L_percentage(ls, 50))\n",
    "    print(\"N90\", N_percentage(ls, 90))\n",
    "    print(\"L90\", L_percentage(ls, 90))\n",
    "    print(\"Max scaffold:\", mx)\n",
    "    mi=\"Min scaffold: \"+str(mi)\n",
    "    return mi\n",
    "\n",
    "print(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7871b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ncoll [745751, 742537, 739748, 716602, 714651, 702208, 675346, 666816, 654595, 629517, 596352, 582573, 574960, 573434, 562643, 516869, 465823, 384502, 328634, 270161]\n",
      "Lcoll [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 24, 26, 29]\n"
     ]
    }
   ],
   "source": [
    "def N_collection(ls):\n",
    "\n",
    "    coll=[]\n",
    "    for point in range(0, 100, 5):\n",
    "        coll.append(N_percentage(ls, point))\n",
    "    return (coll)\n",
    "\n",
    "def L_collection(ls):\n",
    "    coll=[]\n",
    "    for point in range(0, 100, 5):\n",
    "        coll.append(L_percentage(ls, point))\n",
    "    return (coll)\n",
    "\n",
    "ls, mx, mi=length(file)\n",
    "print(\"Ncoll\",N_collection(ls))\n",
    "print(\"Lcoll\",L_collection(ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e4e74",
   "metadata": {},
   "source": [
    "\n",
    "B - compute now the Nseries for the Caenorhabditis afra assembly. As file is larger than 40 MB, you'll need to uncompress the .zip file provided in the Aula ESCI. Finally, examine the fasta:   \n",
    "\n",
    "   4.1. Which assembly is longer this or the plant contaminants one?\n",
    "   \n",
    "   4.2. Which one includes the shortest scaffolds?\n",
    "   \n",
    "   4.3. Which one is more contiguous attending to the N50?\n",
    "   \n",
    "   4.4. Is the N50 doing a fair comparison between both assemblies? why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "638c2a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant\n",
      "min plant\n"
     ]
    }
   ],
   "source": [
    "file=\"plant_contaminants.fa\"\n",
    "plant=[plant_ls, plant_mx, plant_mn]=length(file)\n",
    "\n",
    "file=\"nxCaeAfra1.1_assembly.fa\"\n",
    "Cae=[Cls, Cmx, Cmn]=length(file)\n",
    "\n",
    "if len(plant_ls)>len(Cls):\n",
    "    print(\"plant assembly is longer\")\n",
    "elif len(plant_ls)<len(Cls):\n",
    "    print(\"Cae\")\n",
    "else:\n",
    "    print(\"equal\")\n",
    "\n",
    "if plant_mx<Cmx:\n",
    "    print(\"min plant\")\n",
    "elif plant_mx>Cmx:\n",
    "    print(\"min Cae\")\n",
    "else:\n",
    "    print(\"equal\")\n",
    "\n",
    "def comparer(term, plant, Cae):#nope\n",
    "    if plant>Cae:\n",
    "        print(\"Plant\")\n",
    "    elif plant<Cae:\n",
    "        print(\"Cae\")\n",
    "    else:\n",
    "        print(\"equal\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
