'''
@author: Eloi
'''
from Alias_Vose import RandomMultinomial

import math

'''
A class to code methods that are used in HMM.
'''
class HiddenMarkovModel(object):

	'''
	Create an object HiddenMarkovModel with transition states and emission probabilities for each state
	Transition is a dictionary where, for each state, we count the probability to move to another state
	Emission is a dictionary where, for each state, we store the probabilities of each category
	'''
	def __init__(self, transition, emission):
		if transition.__len__()!=emission.__len__():
			raise Exception("for each state, we must have an emission probability vector, but found " + transition.__len__() + " " + emission.__len__())        
		self.n = transition.__len__()
		self.transition = transition
		self.emission = emission
		'''
		dictionary to store the random multinomial 
		'''
		self.random_transition = {}
		self.random_emission = {}  
		
		'''
		Initialize the random multinomial
		'''
		for key in self.transition:
			self.random_transition[key] = RandomMultinomial(list(transition[key].values()))
			self.random_emission[key] = RandomMultinomial(list(emission[key].values()))
		
		
	'''
	Compute a sequence of length using a prior probabilities dictionary of the states to start the chain.
	Return the sequence and its hidden states
	'''    
	def generate_sequence(self, length_sequence, prior_probabilities):
		chain = []
		hidden_states = []
		'''
		Iterate over the i elements of the sequence, generating given the emission probabilities and transition probabilities a new .
		'''
		pr = RandomMultinomial(list(prior_probabilities.values()))
		state = list(prior_probabilities.keys())[pr.sample()]
		for i in range(length_sequence):
			'''
			from the state, use its emission probability to sample one element
			'''
			category = list(self.emission[state].keys())[self.random_emission[state].sample()]
			chain.append(category)
			hidden_states.append(state)
			state = list(self.transition[state].keys())[self.random_transition[state].sample()]
		output = [chain,hidden_states]
		return(output)
	
	
	'''
	Compute the log probability of the sequence using forward algorithm. It uses the scale algorithm (Rabiner) to prevent underflow
	'''
	def log_probability_sequence_using_scaling(self, sequence, prior_probabilities):
		f_i = prior_probabilities.copy()
		S = 0
		
		for i in range(len(sequence)):
			s_ii = 0
			f_ii = {}
	
			for key_ii in f_i:
				a = 0
				
				for key_i in f_i:
					a = a + self.transition[key_i][key_ii] * f_i[key_i]
					
				a = a*self.emission[key_ii][sequence[i]]
				f_ii[key_ii] = a
				s_ii = s_ii + a
				
	  
			for key_ii in f_ii:
				f_i[key_ii] = f_ii[key_ii]/s_ii            
		   
			S = S + math.log(s_ii)
		
		return(S)
		
		  
	def log_probability_sequence_without_scaling(self, sequence, prior_probabilities):
		f_i = prior_probabilities.copy()
		S = 0

		for i in range(len(sequence)):
			f_ii = {}
			
			for key_ii in f_i:
				a = 0
				
				for key_i in f_i:
					a = a + self.transition[key_i][key_ii] * f_i[key_i]

				a = a * self.emission[key_ii][sequence[i]]
				f_ii[key_ii] = a

			f_i = f_ii

		S = math.log(sum(f_i.values()))

		return S

	
	
	'''
	given a sequence generated by a HiddenMarkovModel object, estimate the emission probabilities
	of the different categories for each state
	'''
	def estimate_emission_probabilities(self,seq):
		prob_dict = {"S":{"G":0,"C":0,"T":0,"A":0}, "L":{"G":0,"C":0,"T":0,"A":0}}
		nucs = seq[0]
		states = seq[1]
		for pos in range(len(nucs)):
			prob_dict[states[pos]][nucs[pos]] += 1
		
		for key_1 in prob_dict.keys():
			sum_values = sum(prob_dict[key_1].values())
			
			for key_2 in prob_dict[key_1].keys():
				if prob_dict[key_1][key_2] != 0:
					prob_dict[key_1][key_2] = prob_dict[key_1][key_2]/sum_values
					
		return prob_dict
	
	
	'''
	given a sequence generated by a HiddenMarkovModel object, estimate the transition probabilities
	between states
	'''    
	def estimate_transition_probabilities(self,seq):
		states = seq[1]
		trans_dict = {"S":{"S":0,"L":0},"L":{"S":0,"L":0}};
		for pos in range(len(states)-1):
			trans_dict[states[pos]][states[pos+1]] += 1
			
		for key_1 in trans_dict.keys():
			sum_values = sum(trans_dict[key_1].values())
			
			for key_2 in trans_dict[key_1].keys():
				if trans_dict[key_1][key_2] != 0:
					trans_dict[key_1][key_2] = trans_dict[key_1][key_2]/sum_values
					
		return trans_dict


def main():
	transition_probability = {"S":{"S":0.9,"L":0.1},"L":{"S":0.2,"L":0.8}};
	emission_probability = {"S":{"G":0.1,"C":0.2,"T":0.2,"A":0.5}, "L":{"G":0.01,"C":0.1,"T":0.3,"A":0.59}}
	hmm = HiddenMarkovModel(transition_probability, emission_probability)
	
	prior_probability = {"S":0.5, "L":0.5}
	
	seq = hmm.generate_sequence(600, prior_probability)

	emission_prob = hmm.estimate_emission_probabilities(seq);

	for key in emission_prob:
		print(key, emission_prob[key])
		
	transition_prob = hmm.estimate_transition_probabilities(seq)
	
	for key in transition_prob:
		print(key, transition_prob[key]) 

		
	print(hmm.log_probability_sequence_using_scaling(seq[0], prior_probability))

	print(hmm.log_probability_sequence_without_scaling(seq[0], prior_probability))


	
if __name__ == "__main__":
	main () 
